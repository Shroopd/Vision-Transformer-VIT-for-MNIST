Windows PowerShell
Copyright (C) Microsoft Corporation. All rights reserved.

Install the latest PowerShell for new features and improvements! https://aka.ms/PSWindows

PS C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST> & C:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/.venv/Scripts/Activate.ps1
(.venv) PS C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST> & c:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST\.venv\Scripts\Activate.ps1
(.venv) PS C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST> & C:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/.venv/Scripts/python.exe c:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/foobard.py
Using device: cuda
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.42421296..2.8214867].
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
ViT                                                1,632
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 544
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        16,672
│    │    └─ModuleList: 3-2                        16,672
│    │    └─ModuleList: 3-3                        16,672
│    │    └─ModuleList: 3-4                        16,672
│    │    └─ModuleList: 3-5                        16,672
│    │    └─ModuleList: 3-6                        16,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 330
===========================================================================
Total params: 102,602
Trainable params: 102,602
Non-trainable params: 0
===========================================================================
Epoch: 1
[    0/60000 (  0%)]  Loss: 0.9486
[10000/60000 ( 17%)]  Loss: 0.9434
[20000/60000 ( 33%)]  Loss: 0.9244
[30000/60000 ( 50%)]  Loss: 0.9404
[40000/60000 ( 67%)]  Loss: 0.9293
[50000/60000 ( 83%)]  Loss: 0.7969

Average test loss: 0.8727  Accuracy: 6909/10000 (69.09%)

Epoch: 2
[    0/60000 (  0%)]  Loss: 0.8102
[10000/60000 ( 17%)]  Loss: 1.0327
[20000/60000 ( 33%)]  Loss: 0.9138
[30000/60000 ( 50%)]  Loss: 0.7587
[40000/60000 ( 67%)]  Loss: 0.8104
[50000/60000 ( 83%)]  Loss: 0.7346

Average test loss: 0.8804  Accuracy: 6915/10000 (69.15%)

Epoch: 3
[    0/60000 (  0%)]  Loss: 0.8988
[10000/60000 ( 17%)]  Loss: 0.8170
[20000/60000 ( 33%)]  Loss: 0.7638
[30000/60000 ( 50%)]  Loss: 0.6138
[40000/60000 ( 67%)]  Loss: 0.8822
[50000/60000 ( 83%)]  Loss: 0.8180

Average test loss: 0.8304  Accuracy: 7140/10000 (71.40%)

Epoch: 4
[    0/60000 (  0%)]  Loss: 0.7258
[10000/60000 ( 17%)]  Loss: 0.6407
[20000/60000 ( 33%)]  Loss: 0.7568
[30000/60000 ( 50%)]  Loss: 0.6175
[40000/60000 ( 67%)]  Loss: 0.9696
[50000/60000 ( 83%)]  Loss: 0.8331

Average test loss: 0.7726  Accuracy: 7331/10000 (73.31%)

Epoch: 5
[    0/60000 (  0%)]  Loss: 0.9067
[10000/60000 ( 17%)]  Loss: 0.7214
[20000/60000 ( 33%)]  Loss: 0.6855
[30000/60000 ( 50%)]  Loss: 0.7778
[40000/60000 ( 67%)]  Loss: 0.8592
[50000/60000 ( 83%)]  Loss: 0.6021

Average test loss: 0.7484  Accuracy: 7426/10000 (74.26%)

Epoch: 6
[    0/60000 (  0%)]  Loss: 0.5084
[10000/60000 ( 17%)]  Loss: 0.8144
[20000/60000 ( 33%)]  Loss: 0.7746
[30000/60000 ( 50%)]  Loss: 0.8790
[40000/60000 ( 67%)]  Loss: 0.8436
[50000/60000 ( 83%)]  Loss: 0.7169

Average test loss: 0.7759  Accuracy: 7338/10000 (73.38%)

Epoch: 7
[    0/60000 (  0%)]  Loss: 0.7659
[10000/60000 ( 17%)]  Loss: 0.7133
[20000/60000 ( 33%)]  Loss: 0.7291
[30000/60000 ( 50%)]  Loss: 0.7503
[40000/60000 ( 67%)]  Loss: 0.6161
[50000/60000 ( 83%)]  Loss: 0.6282

Average test loss: 0.7582  Accuracy: 7397/10000 (73.97%)

Epoch: 8
[    0/60000 (  0%)]  Loss: 0.7410
[10000/60000 ( 17%)]  Loss: 0.7661
[20000/60000 ( 33%)]  Loss: 0.5829
[30000/60000 ( 50%)]  Loss: 0.6865
[40000/60000 ( 67%)]  Loss: 0.7551
[50000/60000 ( 83%)]  Loss: 0.7509

Average test loss: 0.6931  Accuracy: 7655/10000 (76.55%)

Epoch: 9
[    0/60000 (  0%)]  Loss: 0.4947
[10000/60000 ( 17%)]  Loss: 0.5875
[20000/60000 ( 33%)]  Loss: 0.5700
[30000/60000 ( 50%)]  Loss: 0.8337
[40000/60000 ( 67%)]  Loss: 0.7310
[50000/60000 ( 83%)]  Loss: 0.7258

Average test loss: 0.6907  Accuracy: 7710/10000 (77.10%)

Epoch: 10
[    0/60000 (  0%)]  Loss: 0.6745
[10000/60000 ( 17%)]  Loss: 0.7147
[20000/60000 ( 33%)]  Loss: 0.6153
[30000/60000 ( 50%)]  Loss: 0.7055
[40000/60000 ( 67%)]  Loss: 0.7736
[50000/60000 ( 83%)]  Loss: 0.6104

Average test loss: 0.6720  Accuracy: 7708/10000 (77.08%)

Execution time: 136.16 seconds

Average test loss: 0.6720  Accuracy: 7708/10000 (77.08%)

plot_confusion_matrix(model, test_loader)
plot_predictions(model, test_loader)
(.venv) PS C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST> & C:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/.venv/Scripts/python.exe c:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/foobard.py
Using device: cuda
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.42421296..2.8214867].
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
ViT                                                1,632
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 544
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        16,672
│    │    └─ModuleList: 3-2                        16,672
│    │    └─ModuleList: 3-3                        16,672
│    │    └─ModuleList: 3-4                        16,672
│    │    └─ModuleList: 3-5                        16,672
│    │    └─ModuleList: 3-6                        16,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 330
===========================================================================
Total params: 102,602
Trainable params: 102,602
Non-trainable params: 0
===========================================================================
Epoch: 1
[    0/60000 (  0%)]  Loss: 0.4623
[10000/60000 ( 17%)]  Loss: 0.6027
[20000/60000 ( 33%)]  Loss: 0.5129
[30000/60000 ( 50%)]  Loss: 0.5416
[40000/60000 ( 67%)]  Loss: 0.5938
[50000/60000 ( 83%)]  Loss: 0.5078

Average test loss: 0.6229  Accuracy: 7889/10000 (78.89%)

Epoch: 2
[    0/60000 (  0%)]  Loss: 0.4689
[10000/60000 ( 17%)]  Loss: 0.7755
[20000/60000 ( 33%)]  Loss: 0.6580
[30000/60000 ( 50%)]  Loss: 0.5624
[40000/60000 ( 67%)]  Loss: 0.4789
[50000/60000 ( 83%)]  Loss: 0.5117

Average test loss: 0.6295  Accuracy: 7895/10000 (78.95%)

Epoch: 3
[    0/60000 (  0%)]  Loss: 0.4793
[10000/60000 ( 17%)]  Loss: 0.6760
[20000/60000 ( 33%)]  Loss: 0.7100
[30000/60000 ( 50%)]  Loss: 0.5403
[40000/60000 ( 67%)]  Loss: 0.7061
[50000/60000 ( 83%)]  Loss: 0.5483

Average test loss: 0.6024  Accuracy: 7975/10000 (79.75%)

Epoch: 4
[    0/60000 (  0%)]  Loss: 0.5885
[10000/60000 ( 17%)]  Loss: 0.4774
[20000/60000 ( 33%)]  Loss: 0.5992
[30000/60000 ( 50%)]  Loss: 0.5067
[40000/60000 ( 67%)]  Loss: 0.7379
[50000/60000 ( 83%)]  Loss: 0.5594

Average test loss: 0.5971  Accuracy: 7969/10000 (79.69%)

Epoch: 5
[    0/60000 (  0%)]  Loss: 0.7037
[10000/60000 ( 17%)]  Loss: 0.6342
[20000/60000 ( 33%)]  Loss: 0.4349
[30000/60000 ( 50%)]  Loss: 0.5199
[40000/60000 ( 67%)]  Loss: 0.6561
[50000/60000 ( 83%)]  Loss: 0.4565

Average test loss: 0.5733  Accuracy: 8073/10000 (80.73%)

Epoch: 6
[    0/60000 (  0%)]  Loss: 0.5636
[10000/60000 ( 17%)]  Loss: 0.6707
[20000/60000 ( 33%)]  Loss: 0.6722
[30000/60000 ( 50%)]  Loss: 0.5719
[40000/60000 ( 67%)]  Loss: 0.4638
[50000/60000 ( 83%)]  Loss: 0.3302

Average test loss: 0.5765  Accuracy: 8056/10000 (80.56%)

Epoch: 7
[    0/60000 (  0%)]  Loss: 0.5621
[10000/60000 ( 17%)]  Loss: 0.4178
[20000/60000 ( 33%)]  Loss: 0.5273
[30000/60000 ( 50%)]  Loss: 0.5027
[40000/60000 ( 67%)]  Loss: 0.4765
[50000/60000 ( 83%)]  Loss: 0.5515

Average test loss: 0.5794  Accuracy: 8074/10000 (80.74%)

Epoch: 8
[    0/60000 (  0%)]  Loss: 0.5309
[10000/60000 ( 17%)]  Loss: 0.8155
[20000/60000 ( 33%)]  Loss: 0.4977
[30000/60000 ( 50%)]  Loss: 0.6204
[40000/60000 ( 67%)]  Loss: 0.6239
[50000/60000 ( 83%)]  Loss: 0.5446

Average test loss: 0.5665  Accuracy: 8105/10000 (81.05%)

Epoch: 9
[    0/60000 (  0%)]  Loss: 0.4821
[10000/60000 ( 17%)]  Loss: 0.5205
[20000/60000 ( 33%)]  Loss: 0.4399
[30000/60000 ( 50%)]  Loss: 0.5732
[40000/60000 ( 67%)]  Loss: 0.5038
[50000/60000 ( 83%)]  Loss: 0.7659

Average test loss: 0.5587  Accuracy: 8154/10000 (81.54%)

Epoch: 10
[    0/60000 (  0%)]  Loss: 0.5556
[10000/60000 ( 17%)]  Loss: 0.5283
[20000/60000 ( 33%)]  Loss: 0.5627
[30000/60000 ( 50%)]  Loss: 0.5339
[40000/60000 ( 67%)]  Loss: 0.5682
[50000/60000 ( 83%)]  Loss: 0.5325

Average test loss: 0.5469  Accuracy: 8213/10000 (82.13%)

Execution time: 136.19 seconds

Average test loss: 0.5469  Accuracy: 8213/10000 (82.13%)

plot_confusion_matrix(model, test_loader)
plot_predictions(model, test_loader)
(.venv) PS C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST> & C:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/.venv/Scripts/python.exe c:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/foobard.py
Using device: cuda
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.42421296..2.8214867].
Traceback (most recent call last):
  File "c:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST\foobard.py", line 418, in <module>
    model.load_state_dict(torch.load(file, weights_only=True))
                          ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST\.venv\Lib\site-packages\torch\serialization.py", line 1500, in load
    with _open_file_like(f, "rb") as opened_file:
         ~~~~~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST\.venv\Lib\site-packages\torch\serialization.py", line 768, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST\.venv\Lib\site-packages\torch\serialization.py", line 749, in __init__
    super().__init__(open(name, mode))  # noqa: SIM115
                     ~~~~^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'model3.pt'
(.venv) PS C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST> & C:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/.venv/Scripts/python.exe c:/Users/dj/OneDrive/Documents/GitHub/Vision-Transformer-VIT-for-MNIST/foobard.py
Using device: cuda
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.42421296..2.8214867].
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
ViT                                                1,632
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 544
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        13,600
│    │    └─ModuleList: 3-2                        13,600
│    │    └─ModuleList: 3-3                        13,600
│    │    └─ModuleList: 3-4                        13,600
│    │    └─ModuleList: 3-5                        13,600
│    │    └─ModuleList: 3-6                        13,600
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 330
===========================================================================
Total params: 84,170
Trainable params: 84,170
Non-trainable params: 0
===========================================================================
Epoch: 1
[    0/60000 (  0%)]  Loss: 2.5137
[10000/60000 ( 17%)]  Loss: 0.8120
[20000/60000 ( 33%)]  Loss: 0.6137
[30000/60000 ( 50%)]  Loss: 0.4403
[40000/60000 ( 67%)]  Loss: 0.3264
[50000/60000 ( 83%)]  Loss: 0.3614

Average test loss: 0.2736  Accuracy: 9182/10000 (91.82%)

Epoch: 2
[    0/60000 (  0%)]  Loss: 0.3355
[10000/60000 ( 17%)]  Loss: 0.3952
[20000/60000 ( 33%)]  Loss: 0.2826
[30000/60000 ( 50%)]  Loss: 0.2355
[40000/60000 ( 67%)]  Loss: 0.2010
[50000/60000 ( 83%)]  Loss: 0.1567

Average test loss: 0.2794  Accuracy: 9077/10000 (90.77%)

Epoch: 3
[    0/60000 (  0%)]  Loss: 0.3896
[10000/60000 ( 17%)]  Loss: 0.2171
[20000/60000 ( 33%)]  Loss: 0.1550
[30000/60000 ( 50%)]  Loss: 0.2655
[40000/60000 ( 67%)]  Loss: 0.0991
[50000/60000 ( 83%)]  Loss: 0.1776

Average test loss: 0.1516  Accuracy: 9534/10000 (95.34%)

Epoch: 4
[    0/60000 (  0%)]  Loss: 0.0753
[10000/60000 ( 17%)]  Loss: 0.0773
[20000/60000 ( 33%)]  Loss: 0.0817
[30000/60000 ( 50%)]  Loss: 0.0639
[40000/60000 ( 67%)]  Loss: 0.1418
[50000/60000 ( 83%)]  Loss: 0.1023

Average test loss: 0.1317  Accuracy: 9594/10000 (95.94%)

Epoch: 5
[    0/60000 (  0%)]  Loss: 0.1515
[10000/60000 ( 17%)]  Loss: 0.1891
[20000/60000 ( 33%)]  Loss: 0.0437
[30000/60000 ( 50%)]  Loss: 0.1244
[40000/60000 ( 67%)]  Loss: 0.1159
[50000/60000 ( 83%)]  Loss: 0.1474

Average test loss: 0.1283  Accuracy: 9605/10000 (96.05%)

Epoch: 6
[    0/60000 (  0%)]  Loss: 0.1717
[10000/60000 ( 17%)]  Loss: 0.1175
[20000/60000 ( 33%)]  Loss: 0.0666
[30000/60000 ( 50%)]  Loss: 0.1169
[40000/60000 ( 67%)]  Loss: 0.1153
[50000/60000 ( 83%)]  Loss: 0.1000

Average test loss: 0.1099  Accuracy: 9671/10000 (96.71%)

Epoch: 7
[    0/60000 (  0%)]  Loss: 0.0900
[10000/60000 ( 17%)]  Loss: 0.0996
[20000/60000 ( 33%)]  Loss: 0.0823
[30000/60000 ( 50%)]  Loss: 0.0260
[40000/60000 ( 67%)]  Loss: 0.0705
[50000/60000 ( 83%)]  Loss: 0.1276

Average test loss: 0.1016  Accuracy: 9686/10000 (96.86%)

Epoch: 8
[    0/60000 (  0%)]  Loss: 0.1895
[10000/60000 ( 17%)]  Loss: 0.1045
[20000/60000 ( 33%)]  Loss: 0.1553
[30000/60000 ( 50%)]  Loss: 0.0588
[40000/60000 ( 67%)]  Loss: 0.0916
[50000/60000 ( 83%)]  Loss: 0.0947

Average test loss: 0.0891  Accuracy: 9721/10000 (97.21%)

Epoch: 9
[    0/60000 (  0%)]  Loss: 0.0633
[10000/60000 ( 17%)]  Loss: 0.0177
[20000/60000 ( 33%)]  Loss: 0.0412
[30000/60000 ( 50%)]  Loss: 0.1711
[40000/60000 ( 67%)]  Loss: 0.0756
[50000/60000 ( 83%)]  Loss: 0.0704

Average test loss: 0.0901  Accuracy: 9717/10000 (97.17%)

Epoch: 10
[    0/60000 (  0%)]  Loss: 0.0824
[10000/60000 ( 17%)]  Loss: 0.0355
[20000/60000 ( 33%)]  Loss: 0.0707
[30000/60000 ( 50%)]  Loss: 0.0151
[40000/60000 ( 67%)]  Loss: 0.0447
[50000/60000 ( 83%)]  Loss: 0.0607

Average test loss: 0.1234  Accuracy: 9609/10000 (96.09%)

Execution time: 239.79 seconds

Average test loss: 0.1234  Accuracy: 9609/10000 (96.09%)

plot_confusion_matrix(model, test_loader)
plot_predictions(model, test_loader)
(.venv) PS C:\Users\dj\OneDrive\Documents\GitHub\Vision-Transformer-VIT-for-MNIST>